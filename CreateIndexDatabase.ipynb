{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fb49e3c1fda40bbb45aeba14a11180c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_395025a09ba74ab1a2f94e6af1c58c91",
              "IPY_MODEL_32d905b50cc7475eb19c6194bacbeed8",
              "IPY_MODEL_c745ff6c507b45e0b1cd76ca280e0c99"
            ],
            "layout": "IPY_MODEL_c3c76564eba64c1ab2afbbcc5f955641"
          }
        },
        "395025a09ba74ab1a2f94e6af1c58c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1d75635ce8472a9713aa5016986112",
            "placeholder": "​",
            "style": "IPY_MODEL_3476f0baeb2f45fa9307bcb026b7c57b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "32d905b50cc7475eb19c6194bacbeed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584a4f7a04fe4dbcba8be41660bc4c1f",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9373c32f29934178a7d222797097ca43",
            "value": 4
          }
        },
        "c745ff6c507b45e0b1cd76ca280e0c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c0f7d28e754f5e89ba243f14e569b8",
            "placeholder": "​",
            "style": "IPY_MODEL_aff14a520c4b4f03bcbbabfe2946075b",
            "value": " 4/4 [03:08&lt;00:00, 39.92s/it]"
          }
        },
        "c3c76564eba64c1ab2afbbcc5f955641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1d75635ce8472a9713aa5016986112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3476f0baeb2f45fa9307bcb026b7c57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584a4f7a04fe4dbcba8be41660bc4c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9373c32f29934178a7d222797097ca43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7c0f7d28e754f5e89ba243f14e569b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff14a520c4b4f03bcbbabfe2946075b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyf7ASePYVgL",
        "outputId": "fb9421d5-b134-4869-bb58-8fcb5010bcae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.35.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install usearch\n",
        "!pip install torch datasets bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install accelerate\n",
        "!pip install sentence-transformers\n",
        "!pip install -i https://test.pypi.org/simple/ bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pm_jKBQB2Xk",
        "outputId": "ff884ddf-3383-407a-b16c-686431c671fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: usearch in /usr/local/lib/python3.10/dist-packages (2.8.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from usearch) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from usearch) (4.66.1)\n",
            "Requirement already satisfied: ucall in /usr/local/lib/python3.10/dist-packages (from usearch) (0.5.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from ucall->usearch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-0crh90us\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-0crh90us\n",
            "  Resolved https://github.com/huggingface/transformers to commit bc72b4e2cdcbc80d5f56731f35dbc9c18b4c8de6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2023.11.17)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.37.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/truy van thong tin dpt/ImageRetrieval"
      ],
      "metadata": {
        "id": "0rS0_ekhrbF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcef9423-6f0c-4705-e9fc-55afa73b93c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/truy van thong tin dpt/ImageRetrieval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import InstructBlipForConditionalGeneration, InstructBlipProcessor"
      ],
      "metadata": {
        "id": "-6GLtIGjCBId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "0fb49e3c1fda40bbb45aeba14a11180c",
            "395025a09ba74ab1a2f94e6af1c58c91",
            "32d905b50cc7475eb19c6194bacbeed8",
            "c745ff6c507b45e0b1cd76ca280e0c99",
            "c3c76564eba64c1ab2afbbcc5f955641",
            "2b1d75635ce8472a9713aa5016986112",
            "3476f0baeb2f45fa9307bcb026b7c57b",
            "584a4f7a04fe4dbcba8be41660bc4c1f",
            "9373c32f29934178a7d222797097ca43",
            "b7c0f7d28e754f5e89ba243f14e569b8",
            "aff14a520c4b4f03bcbbabfe2946075b"
          ]
        },
        "id": "Nay-GftTBq9m",
        "outputId": "5ebe82fc-fa7d-4df4-82d7-3b1d6b24e366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fb49e3c1fda40bbb45aeba14a11180c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "model = InstructBlipForConditionalGeneration.from_pretrained(\n",
        "    'Salesforce/instructblip-vicuna-7b',\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "processor = InstructBlipProcessor.from_pretrained(\n",
        "    'Salesforce/instructblip-vicuna-7b',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "pwoXxSeRM-rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests"
      ],
      "metadata": {
        "id": "gZli17_2aW9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets =[('detection-datasets/fashionpedia',None,'val')]\n",
        "datasets = [('phiyodr/coco2017', None, 'validation')]\n",
        "prompt1 = \"describe this image in full detail, describe each and every aspect of the image so the artist could re create the image\"\n",
        "prompt2 = \"create an extensive description of this image\"\n",
        "counter = 169\n",
        "for name, config, split in datasets:\n",
        "    d = load_dataset(name, config, split=split)\n",
        "    for idx in range(500, len(d)):\n",
        "        url = d[idx][\"coco_url\"]\n",
        "        image = Image.open(requests.get(url, stream=True).raw)\n",
        "        # image = d[idx][\"image\"]\n",
        "        desc = ''\n",
        "        for _prompt in [prompt1, prompt2]:\n",
        "            inputs = processor(\n",
        "                images=image,\n",
        "                text=_prompt,\n",
        "                return_tensors='pt'\n",
        "            ).to(model.device, torch.bfloat16)\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                do_sample=False,\n",
        "                num_beams=10,\n",
        "                max_length=512,\n",
        "                min_length=16,\n",
        "                top_p=0.9,\n",
        "                repetition_penalty=1.5,\n",
        "                temperature=1,\n",
        "            )\n",
        "            generated_text = processor.batch_decode(\n",
        "                outputs,\n",
        "                skip_special_tokens=True,\n",
        "            )[0].strip()\n",
        "\n",
        "            desc += generated_text + \" \"\n",
        "\n",
        "        desc = desc.strip()\n",
        "        if not os.path.exists('images'):\n",
        "          os.makedirs('images')\n",
        "        image.save(f'images/{counter}.jpg')\n",
        "        print(counter, desc)\n",
        "\n",
        "        with open(\"description.csv\", 'a') as f:\n",
        "            f.write(f\"{counter}, {desc}\\n\")\n",
        "\n",
        "        counter += 1\n",
        "        if counter >= 500:\n",
        "            break\n",
        "\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSLdnu9rC2wa",
        "outputId": "de74e620-0fc9-46a9-d3b2-ae9278cc7163"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 based on the image description The image depicts a woman wearing a white tennis outfit playing tennis on a grassy surface. She is actively engaged in the game, running and swinging her tennis racket to hit the ball. There are several tennis balls scattered around the scene, indicating that the game is in progress. In total, there are nine tennis balls visible in the image, with some located closer to the woman and others positioned further away. a woman swinging a tennis racket at a ball on a tennis court\n",
            "65 based on the image description a young girl is seen brushing her teeth with a blue toothbrush. She is wearing a green shirt and appears to be focused on brushing her teeth diligently. In addition to the toothbrush, there are two cups visible in the scene, one on the left side of the image and another on the right side. The presence of these cups suggests that the girl might be using them to rinse her mouth after brushing her teeth. Overall, the image depicts a young girl taking care of her dental hygiene, emphasizing the importance of regular brushing and rinsing for maintaining good oral health. a young girl brushing her teeth with a blue toothbrush\n",
            "66 based on the image description there is a young boy sitting on a couch, wearing a black shirt, and holding a cell phone in his hand. He appears to be engrossed in what he's doing, possibly playing a video game or watching a movie. There is also a teddy bear on the couch next to the boy, adding to the cozy and relaxed atmosphere of the scene. a young boy sitting on a couch with a pink blanket\n",
            "67 there are three men sitting on a couch in a dimly lit room, laughing and enjoying each other's company. Two of the men are holding Nintendo Wii remotes, which they are using to play a video game together. The third man is not participating in the gaming activity but appears to be observing and enjoying the others' fun. There is also a television in the room, positioned near the couch where the men are sitting. three men sitting on a couch laughing and playing a video game\n",
            "68 based on the image description there is a long wooden dining table in the center of the room, surrounded by several chairs. There are two red chairs placed near the table, one on the left side and the other on the right side. In addition to the chairs, there are three bookshelves lined up against the wall, filled with various books. A couch can be seen on the left side of the room, positioned close to the dining table. On the right side of the room, there is another couch, which appears to be more spacious than the first one. Overall, the room has a cozy and inviting atmosphere, perfect for relaxation and social gatherings. there is a dining room with a table and bench in it\n",
            "69 based on the image description there are two couches in the living room, one on the left side of the room and the other on the right side of the room. there is also a dining table in the center of the room, surrounded by four chairs. in addition to the furniture, there are several potted plants scattered throughout the room, adding a touch of greenery and life to the space. there is also a vase filled with flowers on the left side of the room, near one of the couches, and another vase filled with flowers on the right side of the room, near the other couch. overall, the living room exudes a warm and inviting atmosphere, perfect for relaxation and social gatherings. a living room with couches, chairs, and a dining table\n",
            "70 in their own style  there is a spacious living room filled with furniture, including two couches. One of the couches is situated on the left side of the room, while the other is located on the right side. A television is placed in the center of the room, providing entertainment for the occupants. In addition to the couches and television, there are several books scattered throughout the room, adding to the cozy atmosphere. A cat can be seen resting on one of the couches, enjoying the comfortable surroundings. a living room with two couches, a coffee table and a television\n",
            "71 based on the image description a soccer game is taking place on a grassy field. There are several players on the field, some of whom are actively pursuing the soccer ball. In addition to the players, there are several chairs scattered around the field, suggesting that there may be spectators watching the game. A car can also be seen parked near the field, possibly belonging to one of the players or spectators. Overall, the scene depicts a lively and energetic soccer game in progress. a group of girls playing soccer on a field with spectators watching\n",
            "72 based on the image description a group of young children are playing soccer on a grassy field, surrounded by a crowd of adults. There are at least 15 people in the crowd, some of whom are sitting on chairs or benches, while others are standing and watching the kids play. In addition to the soccer game, there are several chairs scattered around the field, providing seating for the spectators. The scene is lively and engaging, showcasing the joy and enthusiasm of both the kids and the adults participating in this outdoor sporting event. a group of kids playing soccer in a field surrounded by adults\n",
            "73 in photoshop a man is standing inside a cave, surrounded by colorful vases and plates hanging on the walls. There are at least 15 vases and plates visible in the scene, ranging from small to large sizes. Some of the vases and plates are stacked on top of each other, while others are arranged in a more organized manner. The man appears to be inspecting or admiring the vases and plates, possibly considering purchasing some of them for his own collection. a room filled with colorful ceramic plates and vases\n",
            "74 The image depicts a man on a snowboard in the middle of a snow-covered field. He is wearing a helmet and appears to be flying a kite, which is visible in the background. In addition to the snowboarder, there are several snowmobiles scattered throughout the scene. There are four snowmobiles in total, each positioned at different distances from the snowboarder. Some of the snowmobiles are closer to the snowboarder, while others are farther away. a snowboarder is flying a kite in the snowy field\n",
            "75 based on the image description a young girl is running through a grassy field, holding a colorful kite in her hand. She appears to be enjoying herself as she runs and flies the kite. In addition to the girl, there are several other people scattered throughout the field, some of whom appear to be playing games or engaging in other activities. Overall, the scene depicts a group of people enjoying the outdoors and participating in various recreational activities. a young girl running through a field with a kite in her hand\n",
            "76 There is a young girl wearing an orange shirt playing with a frisbee on a lush green lawn. She is running and throwing the frisbee with great enthusiasm. In addition to the girl and the frisbee, there are several potted plants scattered throughout the scene. There are two potted plants on the left side of the image, one close to the girl and the other slightly further away. Another potted plant can be seen on the right side of the image, closer to the edge of the lawn. a young girl playing with a frisbee in the grassy yard\n",
            "77 based on this description there is a red fire hydrant in the center of the image, surrounded by several cars parked along the side of the road. In addition to the fire hydrant, there are two traffic lights visible in the scene, one on the left and one on the right side of the road. There are also several trucks scattered throughout the area, including one on the left side of the image and another on the right side. A clock tower can be seen in the background, contributing to the vintage atmosphere of the scene. there is a clock on the corner of an empty street at dusk\n",
            "78 from scratch a baseball game is taking place on a dirt field. There are several baseball players on the field, some of whom are in the process of batting or catching the ball. A cameraman is also present, capturing the action on the field. In addition to the players and the cameraman, there are several chairs scattered around the field, providing seating for the spectators. Overall, the scene depicts a lively and engaging baseball game being played on a dirt field. a group of baseball players on a field with a camera crew filming\n",
            "79 based on this description there is a large city skyline in the background, with several tall buildings visible. In the foreground, there is a river flowing through the city, and boats can be seen sailing along the river. There are at least three boats visible in the scene, one of which is closer to the center of the image, while the other two are positioned further away from each other. Additionally, there is a clock tower visible in the skyline, which serves as an iconic landmark for the city. Overall, the image depicts a scenic view of a bustling city with a river running through it, surrounded by impressive skyscrapers. a view of the city of london from across the river thames\n",
            "80 from scratch a baseball game is taking place, with several players on the field. There are two baseball bats visible in the scene, one being held by a player and the other resting on the ground. In addition to the bats, there are several baseball gloves scattered around the field, likely belonging to the players or umpires. A crowd of spectators can be seen in the background, watching the game unfold. a baseball player holding a bat on a field with an umpire and catcher\n",
            "81 based on the image description this image features a dining table set up for a meal. On the table, there is a large bowl filled with a cheesy pizza-like dish, which appears to be the main attraction of the meal.  In addition to the main dish, there are several other food items scattered around the table, including bread slices, crackers, and chips. A wine glass can also be seen on the table, adding a touch of sophistication to the casual dining scene. Overall, the image depicts a cozy and inviting atmosphere for enjoying a meal with friends or family. there is a bowl of cheesy pizza on the table\n",
            "82 with the same level of detail as the original image there are two women sitting at a desk, each using a laptop computer. One woman has her hands on the keyboard of the laptop, while the other woman is using a mouse to control the cursor on the screen. In addition to the laptops, there are two cell phones placed on the desk, one on the left-hand side and the other on the right-hand side. There are also two chairs positioned near the desk, one on the left-hand side and the other on the right-hand side. a person sitting at a desk with their hands on a laptop keyboard\n",
            "83 There are two life-sized teddy bears placed in front of each other, creating a cute and whimsical display. The first teddy bear is located on the left side of the image, while the second one is situated on the right side. Both bears are adorned with vines and flowers, adding to their lifelike appearance. Additionally, there are several smaller teddy bears scattered throughout the scene, further emphasizing the presence of these beloved stuffed animals. there are two large teddy bears sitting in front of a fence\n",
            "84 in the future\n",
            " In the image, there are three ceramic vases placed on a table. Two of the vases are decorated with paint splatters, while the third one appears to be undecorated. The vases vary in size, with the largest one measuring around 10 inches in height, and the smallest one being around 4.5 inches in height. Additionally, there is a bowl placed on the table, which complements the vases nicely. Overall, this setup provides inspiration for an artist who could potentially recreate the image in the future. there are three ceramic vases sitting on top of a table\n",
            "85 based on this description there is a crowd of people gathered in front of a building, all holding up their cell phones to take pictures or videos. There are at least 10 people in the crowd, some of them standing close together while others are more spread out. In addition to the cell phones, one person can be seen wearing a shirt, and another person is holding a handbag. A traffic light can also be seen in the scene, adding to the bustling atmosphere. a group of people holding up their cell phones in front of a building\n",
            "86 from scratch a man is standing in front of an open oven, reaching inside to retrieve something. He is wearing a blue shirt and appears to be focused on the task at hand. In addition to the man and the oven, there are several bottles scattered around the kitchen area. One bottle can be seen on the left side of the image, while another is located on the right side. There are also two cups present, one on the left side and the other on the right side. there is a man opening an oven with a bag of popcorn\n",
            "87 from scratch a young girl is kneeling in front of an open refrigerator, peering inside to see what's inside. She appears to be very interested in the contents of the refrigerator, possibly searching for something specific. There are several food items visible in the refrigerator, including various bottles, bowls, and cans. Additionally, there are two bowls placed on the floor near the refrigerator, suggesting that they may have been recently removed from the refrigerator. Overall, the scene depicts a curious young girl exploring the contents of her family's refrigerator. there is a little girl peering into an open refrigerator\n",
            "88 There are two toddlers sitting on blue toilet seats in a bathroom. One of the toddlers is holding a hairbrush, while the other appears to be brushing his or her hair. The toddlers are positioned close to each other, with one on the left side and the other on the right side of the image.  In addition to the toddlers and the toilet seats, there are three bottles visible in the scene. Two of the bottles are located on the left side of the image, while the third one is situated on the right side. A cup can also be seen on the right side of the image, next to one of the toddlers. there are two babies sitting on toilets in a bathroom\n",
            "89 based on the image description a vase filled with red and white tulips sits on a table in front of a window. There are 12 tulips arranged in the vase, creating a beautiful display of colorful flowers. A bowl can also be seen on the table near the vase, adding to the overall aesthetic appeal of the scene. a vase of red and white tulips on a window sill\n",
            "90 with the same level of intricacy and attention to detail as the original artist\n",
            " there are two people in the image, a man and a woman. The man is wearing a yellow shirt, while the woman is wearing a pink hat. They both appear to be involved in some sort of crafting or manufacturing process, as they can be seen using various tools such as scissors, a knife, and a pair of scissors. In addition to these tools, there are several books scattered around the room, which suggests that this might be a workspace for someone who enjoys reading and crafting at the same time. Overall, the scene depicts a creative and industrious atmosphere, with the man and woman working diligently on their projects. a man wearing a pink hat is working on a piece of furniture\n",
            "91 in their own style  there is a group of people gathered around a dining table, enjoying each other's company and drinking wine. There are several bottles of wine placed on the table, along with wine glasses for everyone to enjoy. Additionally, there are several chairs arranged around the table, providing comfortable seating for the group. The atmosphere appears to be relaxed and festive, as the group engages in conversation and sips their wine. a group of people sitting around a table with wine bottles and glasses\n",
            "92 based on the image description there are several people sitting on benches along the sidewalk, enjoying the sunny day. there are a total of 12 people in the scene, with some sitting closer to each other and others further apart. one person can be seen wearing a backpack, while another is carrying a handbag. a car can be seen parked on the side of the road, adding to the bustling atmosphere of the cityscape. a traffic light can also be spotted in the scene, indicating the presence of pedestrians and vehicles in the area. a group of people sitting on benches next to each other in a park\n",
            "93 based on the image description a woman is cooking pancakes in a kitchen. She is using a fork to flip the pancakes, and there are several utensils scattered around the kitchen, including knives, forks, and spoons. In addition to the pancakes being cooked, there are multiple bowls filled with various ingredients, such as bananas, apples, and oranges. A bottle can also be seen on the counter near the sink. Overall, the scene depicts a woman preparing a meal in her kitchen, surrounded by various cooking tools and ingredients. a woman flipping pancakes on a stove in a kitchen\n",
            "94 from scratch a mother and a small child are standing in a kitchen, with the mother preparing a meal while the child watches. There is also a dog present in the scene, lying on the floor near the mother and child. Additionally, several bowls can be seen scattered around the kitchen, including one on the countertop and another on the floor. In total, there are four bowls visible in the image. The mother and child appear to be engrossed in the food preparation process, while the dog seems to be enjoying the surroundings as well. a woman is cooking in the kitchen with a child and a dog\n",
            "95 from scratch a woman is standing in front of an old-fashioned kitchen stove. She appears to be cooking or preparing food on the stove, as there are several pots and pans scattered around the area. In addition to the pots and pans, there are also bowls and cups present in the scene. The woman seems to be focused on her cooking task, as she is bent over the stove with her back to the viewer. there is a woman standing in front of a stove with pots and pans\n",
            "96 from scratch a man and his dog are standing in a kitchen area. the man is wearing a blue shirt, while the dog appears to be a yellow labrador retriever. there are several bowls scattered around the kitchen, including one near the man's left foot and another near the dog's right front paw. in addition to the bowls, various utensils can be seen throughout the scene, such as knives, forks, spoons, and a spatula. there are also two chairs present, one on the left side of the image and another on the right side. a man standing in a kitchen next to a brown labrador retriever\n",
            "97 based on the image description there are two sinks in the kitchen, one on the left side of the room and another on the right side of the room. there is also a dining table in the center of the room, surrounded by chairs. a bowl can be seen on top of the sink on the left side of the room, while another bowl is placed on the counter next to the sink on the right side of the room. several bottles are scattered around the room, including one near the sink on the left side, another near the sink on the right side, and a third near the dining table in the center of the room. there is a sink in the center of the kitchen area with a dishwasher next to it\n",
            "98 based on the image description there is a wooden dining table in the center of the room, surrounded by four chairs. There are also two wine glasses placed on the table, as well as several bottles of wine scattered around the room. A refrigerator can be seen on the left side of the room, and an oven is situated on the right side. Additionally, there is a sink located near the refrigerator. The overall atmosphere of the room is cozy and inviting, with a mix of rustic charm and modern appliances. there is a wooden dining table with two chairs in the kitchen\n",
            "99 based on the image description there is a kitchen with white cabinets and stainless steel appliances, including a dishwasher, refrigerator, stove, and microwave. In addition to these appliances, there are several pots and pans hanging on the wall, as well as a bowl placed on the countertop. A vase can also be seen on the countertop, adding a decorative touch to the room. The kitchen appears to be well-maintained and organized, with plenty of space for cooking and preparing meals. a kitchen with white cabinets and stainless steel appliances\n",
            "100 based on the image description there are several bicycles lined up along the sidewalk of a city street. There are at least 10 bicycles visible in the scene, with some placed closer to the viewer and others farther away. In addition to the bicycles, there are several pedestrians walking along the sidewalk, interacting with each other and passing by the bicycles. Some of the pedestrians can be seen further down the sidewalk, while others are closer to the bicycles. An umbrella can also be spotted in the scene, providing shade for one of the pedestrians. Overall, the image depicts a bustling city street with a mix of bicycles, pedestrians, and an umbrella, creating a vibrant and lively atmosphere. there are several motorcycles parked on the side of a city street\n",
            "101 in their own style a horse-drawn carriage is making its way through a busy city street. There are several vehicles on the road, including cars, trucks, and buses, all trying to navigate through the congested area. In addition to the horse-drawn carriage, there are several pedestrians walking along the sidewalks, adding to the bustling atmosphere of the scene. Overall, the image captures the hustle and bustle of a vibrant urban environment. a horse-drawn carriage in the middle of a busy city street\n",
            "102 in photoshop  there is a dirty red toilet located in the center of the room, surrounded by various pipes and wires. There are also several other objects scattered around the room, including a bowl placed near the toilet, a knife on the left side of the room, and a bottle on the right side of the room. The overall appearance of the space suggests that it has not been well-maintained or cleaned recently. there is a red toilet in the corner of a dirty room\n",
            "103 with the same level of detail as the original image there is a young boy standing in front of a dining table. on the table, there is a chocolate cupcake with a lit candle on top. the boy appears to be fascinated by the cupcake, as he is staring at it and reaching out to touch it. around the table, there are several other objects, including two cups, a bowl, and a bottle. one of the cups is placed close to the boy, while the bowl is positioned slightly further away from him. the bottle can be seen in the upper-left corner of the image. overall, the scene depicts a young boy admiring a delicious-looking cupcake with a lit candle on top. a toddler standing in front of a cupcake with a lit candle\n",
            "104 based on the image description there are two toilets in the room, one on the left side and one on the right side of the room. there is also a sink located in the middle of the room, next to the toilets. a bed can be seen in the corner of the room, providing a comfortable sleeping area for the inmates. additionally, there are several bottles scattered throughout the room, likely used for cleaning or hygiene purposes. a jail cell with a toilet and a sink in it\n",
            "105 based on the image description a white toilet sits in a small bathroom. Next to the toilet, there is a small table with a plate of cookies on it. Additionally, there are two cups placed on the floor near the toilet, one on the left side and the other on the right side. A bottle can also be seen on the right side of the room, close to the toilet. The overall atmosphere of the bathroom appears to be clean and well-maintained. there is a toilet in the bathroom with a small table next to it\n",
            "106 with the same level of detail as the original image there is a slice of chocolate cake sitting on a plate, accompanied by a fork. The cake appears to be quite large, taking up most of the space on the plate. Additionally, there are several smaller pieces of cake scattered around the plate, adding to the overall visual appeal of the dessert. Overall, the image captures the essence of a delicious chocolate cake being enjoyed with a fork. a piece of chocolate cake on a plate with a fork\n",
            "107 based on the image description there are two laptops and a desktop computer sitting on a wooden desk. in addition to the electronics, there are several other items scattered around the desk, including two mice, a remote control, and a cell phone. there is also a book placed on the desk, which adds to the overall cluttered appearance of the workspace. there are two laptops and a desktop computer on the desk\n",
            "108 from scratch a man is sitting at a dining table with a plate of food in front of him. He appears to be enjoying his meal, as he is smiling and posing for the camera. On the table, there are several utensils, including knives, forks, and spoons. In the background, there are two couches, one on the left side and another on the right side of the room. A bowl can also be seen on the table, likely containing additional food or condiments. Overall, the scene depicts a man indulging in a delicious meal while enjoying the company of his surroundings. a man sitting at a table with a plate of food in front of him\n",
            "109 in photoshop a large white airplane is flying through the clear blue sky. there are several smaller airplanes visible in the background, but the main focus of the image is the large white airplane that dominates the scene. in total, there are nine airplanes visible in the image, ranging in size from small to large. some of the airplanes are closer to the camera, while others are positioned further away, creating a sense of depth and movement in the scene. an airplane flying through a clear blue sky with its landing gear down\n",
            "110 there are several zebras, giraffes, and antelopes grazing in a dry grassy field. the animals are scattered throughout the scene, with some of them closer to the center of the image and others positioned on the outskirts. there are a total of 12 animals visible in the scene, including three zebras, four giraffes, and five antelopes. the animals appear to be interacting with each other and their surroundings, creating a vibrant and lively atmosphere. a herd of zebras, giraffes and other animals in the wild\n",
            "111 based on the image description  there is a brown dog standing on a wooden bench in a backyard, surrounded by trees and shrubs. The dog appears to be enjoying its surroundings, as it stands confidently on the bench. In addition to the dog, there are several trees and shrubs visible in the scene, contributing to the serene atmosphere of the backyard. A potted plant can also be spotted nearby, adding to the lush greenery of the area. Overall, the image captures a moment of relaxation and enjoyment for the dog in its outdoor surroundings. a dog standing on a bench next to a lemon tree in the backyard\n",
            "112 in black and white  there is a double-decker bus parked on the side of the road, surrounded by pedestrians holding umbrellas to protect themselves from the rain. Nine people can be seen standing near the bus, each holding an umbrella to shield themselves from the downpour. In addition to the umbrellas, there are several handbags scattered throughout the scene, indicating that the pedestrians are carrying their belongings with them as they wait for the bus. a group of people with umbrellas standing in front of a double decker bus\n",
            "113 based on this description there are several traffic lights hanging over a busy city street. There are at least 12 traffic lights visible in the scene, some of which are closer to the center of the image, while others are positioned further away from the viewer. In addition to the traffic lights, there are several cars parked on the side of the road, adding to the bustling atmosphere of the city street. there are a lot of traffic lights hanging from the wires above the road\n",
            "114 In the image, a woman wearing pink high heels is sitting on a colorful wooden bench. She is wearing a pair of pink high heels that match her outfit, which consists of blue jeans. There are two pairs of shoes visible in the image, one placed near the woman's left foot and the other near her right foot. The wooden bench appears to be multi-colored, with various shades of blue, green, and purple contributing to its vibrant appearance. Overall, the image depicts a stylish and fashionable woman enjoying a relaxing moment on a colorful wooden bench. a woman wearing pink shoes sitting on a wooden bench\n",
            "115 based on the image description a man is sitting on a park bench, using a laptop computer. He appears to be engrossed in his work as he focuses on the screen. In addition to the laptop, there are two backpacks visible in the scene, one on the left side of the bench and another near the man's feet. There are also several books scattered around the area, including one on the right side of the bench and another close to the man's backpack. Overall, the image depicts a relaxed atmosphere where the man is able to focus on his work while enjoying the park surroundings. there is a man sitting on a bench with a laptop in his lap\n",
            "116 There is a woman sitting on a bench next to a statue of a woman. She appears to be engrossed in her cell phone, as there are multiple cell phones scattered around the scene. In addition to the woman on the bench, there are several other people visible in the image, some of whom are holding handbags. There is also a fountain present in the scene, contributing to the lively atmosphere. Overall, the image depicts a vibrant public space where people are interacting with each other and enjoying their surroundings. a woman sitting on a bench next to a statue of a woman\n",
            "117 there are two giraffes standing next to each other in a grassy field. One of the giraffes is taller than the other, and they both appear to be eating from the same tree. In addition to the giraffes, there are several trees scattered throughout the field, providing shade and shelter for the animals. A third giraffe can also be spotted in the scene, but it appears to be further away from the other two. a giraffe eating from a tree in the wilderness\n",
            "118 with the same level of detail as the original image this is a black and white photograph of an elderly woman sitting on a park bench. she is wearing a hat and appears to be lost in thought or daydreaming. there are several bags scattered around the scene, including one near the bench where the woman is sitting. in total, there are 10 bags visible in the image, ranging from small handbags to larger luggage-sized bags. a woman sitting on a bench with her hand on her chin\n",
            "119 in black and white  there are three sheep standing next to each other in a fenced-in area. two of the sheep are on the left side of the image, while the third one is on the right side. all three sheep are facing towards the center of the image, creating a symmetrical composition. there are also several trees visible in the background, adding a natural touch to the scene. a black and white photo of three sheep standing next to a wooden fence\n",
            "120 there are two giraffes standing next to each other in a dirt field. One of the giraffes is slightly taller than the other, and they both appear to be eating from a wooden pole. There are several trees visible in the background, providing a natural setting for the giraffes. two giraffes standing next to each other on a dirt field\n",
            "121 based on the image description Three sheep are grazing on a lush green grassy field. There are two adult sheep and one baby sheep in the scene. The adult sheep are positioned closer to the center of the image, while the baby sheep can be found near the right edge of the field. In total, there are four sheep visible in the image. Additionally, there are several trees scattered throughout the field, contributing to the idyllic pastoral setting. a herd of sheep grazing on a lush green pasture\n",
            "122 based on the image description a white fire hydrant sits in the middle of a lush green field, surrounded by tall trees and bushes. There are at least 10 trees visible in the scene, with some located closer to the fire hydrant and others positioned further away. Additionally, there are several bushes scattered throughout the field, contributing to the vibrant and verdant environment. a white and blue fire hydrant in front of a green shrub\n",
            "123 there is a large herd of giraffes running across a lush green field. the giraffes are spread out across the field, with a total of 12 giraffes visible in the image. some of the giraffes are closer to the center of the field, while others are positioned further away from each other. the giraffes seem to be enjoying themselves as they run and interact with their surroundings. a herd of giraffes running across a grassy field\n",
            "124 There is a large window with a view of a snow-covered city in the background. The window appears to be foggy or frosted, obscuring some of the details of the cityscape. In the foreground, there is a bench placed near the window, providing a cozy spot for someone to sit and enjoy the view. Additionally, there are two clocks visible in the scene, one on the left side of the image and another on the right side. These clocks contribute to the overall atmosphere of the image, creating a sense of stillness and tranquility. a view of a city through a window on a cold, rainy day\n",
            "125 based on this description there is a white swan sitting on the shore of a body of water, such as a lake or a river. The swan appears to be relaxing and enjoying the surroundings, with its head resting on the sand near the water's edge. In addition to the swan, there are several other birds visible in the scene, including a seagull, a duck, and a goose. These birds seem to be interacting with each other, creating a lively atmosphere around the swan. a white swan sitting in the sand next to a body of water\n",
            "126 in photoshop/painter etc. There is a red passenger train parked on a train track, surrounded by gravel. The train appears to be stationary, possibly waiting for passengers to board or disembark. In addition to the train, there are several people visible in the scene, some standing near the train and others walking along the tracks. A total of 12 people can be seen in the image, with some closer to the train and others further away. there is a train parked on the tracks next to a train station\n",
            "127 there is a large orange train traveling down a railroad track, surrounded by trees on either side. The train consists of multiple cars, with a total of 10 cars visible in the image. Additionally, there are several trees scattered throughout the scene, providing a natural setting for the train to pass through. a train traveling through the countryside on a sunny day\n",
            "128 The image depicts a yellow and black train traveling down a train track next to a body of water, such as a river or the ocean. There are several people visible in the scene, walking along the train tracks or near the water's edge. In total, 15 people can be seen in the image. Some of them are closer to the train, while others are positioned further away from it. Additionally, there is a car parked near the train tracks, adding to the lively atmosphere of the scene. there is a train traveling down the railroad tracks near a body of water\n",
            "129 based on the image description Three vintage green trucks are parked on a grassy field. One of the trucks is positioned closer to the viewer, while the other two are slightly farther away. The trucks appear to be old and well-maintained, showcasing their vintage charm. In addition to the trucks, there are several cars scattered around the field, adding to the overall vintage atmosphere of the scene. a vintage green pickup truck parked on the grass\n",
            "130 There is a black and white cat wearing a blue stuffed elephant hat on top of its head. The cat is sitting on a stool, which is placed in the middle of the room. In addition to the cat, there are several other objects scattered around the room, including a chair, a bowl, a bottle, and a book. The scene appears to be casual and relaxed, with the cat seemingly enjoying its hat. a black and white cat wearing a blue stuffed elephant on its head\n",
            "131 with the same level of detail as the original image there are two cats in the image, both of which are drinking from glasses. one cat is standing on a chair, while the other is sitting on the floor near the table where the glasses are located. there are several cups scattered around the room, including one on the left side of the image and another on the right side. a bowl can also be seen on the left side of the image, close to the cat sitting on the floor. in addition to the cats and cups, there is a potted plant visible on the right side of the image, adding a touch of greenery to the scene. there is a cat that is drinking out of a glass on a table\n",
            "132 There is a cat perched in the top of a large banana tree, surrounded by green bananas hanging from the branches. The cat seems to be enjoying the shade provided by the tree while keeping an eye on its surroundings. In addition to the cat, there are several banana bunches scattered throughout the scene, adding to the lush and tropical atmosphere. a cat sits in the top of a banana tree with bunches of unripe bananas hanging from it\n",
            "133 the man is wearing a white shirt, black tie, and black pants. he is standing with his hands on his hips, proudly displaying his fashionable attire. there are two other people visible in the image, one on the left side and one on the right side of the man. they are both wearing casual clothing and appear to be interacting with each other. a man wearing a white shirt, black tie and black pants\n",
            "134 in black and white, the image features a man and a little girl sitting together on a couch. the man is wearing a suit, while the little girl is wearing a dress. there are two televisions visible in the scene, one on the left side of the image and another on the right side. in addition to the televisions, there is a bowl placed on the floor near the couch where the man and girl are sitting. a clock can also be seen on the wall, adding to the vintage atmosphere of the image. a man sitting on a couch with a little girl next to him\n",
            "135 based on this description a woman is standing on a railing overlooking the ocean. she is holding a colorful umbrella, providing shade for herself as she gazes out at the water. in addition to the umbrella, there are two handbags visible in the scene, one near the woman and another further down the railing. a third handbag can also be seen in the lower right corner of the image. a woman with a colorful umbrella standing by the water's edge\n",
            "136 based on the image description a woman is sitting on a chair in front of a red wall, holding a white umbrella. She is wearing a white dress and appears to be enjoying the sunny weather. There are two chairs in the scene, one on the left side and the other on the right side of the woman. Additionally, there are two shoes visible in the image, one on the left side and the other on the right side of the woman's chair. a woman holding an umbrella while sitting on a chair in front of a red wall\n",
            "137 based on the image description there is a man dressed in a white shirt and tie, posing for the camera. He is surrounded by a group of people, some of whom are wearing ties as well. There are a total of 12 people in the scene, including the man in the white shirt and tie. Additionally, there are two cell phones visible in the image, one on the left side and another on the right side. a man wearing a tie poses for the camera in a crowded lobby\n",
            "138 there are two women standing in the snow, each holding an umbrella to protect themselves from the harsh weather. One of the women is wearing a coat, while the other has a scarf wrapped around her neck. In addition to the two women, there are three dogs visible in the scene, running and playing in the snow. Two of the dogs are close to the woman with the umbrella, while the third one is positioned slightly further away. a woman walking in the snow with an umbrella and two dogs\n",
            "139 based on this description there is a man wearing a suit and speaking to a group of people. He is standing in front of a large screen displaying his image, captivating the audience's attention. In addition to the man, there are several other people present in the scene, some of whom are listening attentively while others appear to be more casual in their demeanor. The overall atmosphere is one of engagement and interest in the speaker's message. a group of people watching a man giving a speech on a large screen\n",
            "140 with the same level of detail as the original image there is a man riding a bicycle while being pulled by two huskies, a breed of dogs known for their strength and agility. The man is wearing a helmet and appears to be enjoying the ride, while the dogs are focused on their task at hand. Additionally, there are several umbrellas scattered around the scene, suggesting that the event is taking place in a rainy environment. a man riding a bicycle pulled by two huskies\n",
            "141 based on the image description a blue umbrella sits on the sandy beach, providing shade and protection from the sun's rays. underneath the umbrella, a lounge chair is positioned, inviting someone to relax and soak up the sun's warmth. in addition to the lounge chair, there are several smaller chairs scattered around the beach area, offering additional seating options for visitors. a bottle can be seen near the lounge chair, suggesting that someone might be enjoying a refreshing drink while basking in the sun's rays. a lounge chair on the beach under a blue umbrella\n",
            "142 the man is wearing a maroon shirt and a purple tie. he is also wearing glasses, giving him a sophisticated look. there are two pairs of glasses visible in the image, one on the left side of the man's face and the other on the right side. in addition to the glasses, the man is also wearing a pair of shoes. there are two pairs of shoes visible in the image, one on the left side of the man's feet and the other on the right side. overall, the image depicts a well-dressed man with a confident and sophisticated demeanor. a man with glasses wearing a purple shirt and tie\n",
            "143 with the same level of detail as the original image there are two cats laying in the sink, one on the left side and the other on the right side of the sink. they appear to be relaxed and enjoying their surroundings. there is also a bottle of shampoo placed on the counter next to the sink, which suggests that the cats may have been using the sink for their grooming needs. furthermore, there is a tube of toothpaste located near the sink, indicating that the cats might have been brushing their teeth as well. there is a cat curled up in the sink of a bathroom\n",
            "144 from scratch a man is sitting on a couch, wearing a t-shirt, and using a laptop computer. He is holding a cat in his lap as he works on the laptop. In addition to the man and the cat, there are two other cats visible in the scene, one on the left side of the image and another on the right side. a man with a beard and a cat on his lap using a laptop\n",
            "145 with the same level of detail as the original image there are two men standing on the train tracks, watching a train pass by. one man is wearing a blue shirt, while the other is wearing a green shirt. there are also several suitcases scattered around the area, likely belonging to the men waiting for the train. in addition to the men and their luggage, there are several other people visible in the scene, including a woman carrying a purse and another man holding a briefcase. a group of men waiting for a train to arrive at a train station\n",
            "146 based on the image description there are two umbrellas in the image, one large and one small. the large umbrella is placed on top of a wooden picnic table, while the smaller umbrella is positioned next to it. there are also several chairs placed around the picnic table, creating a cozy atmosphere for outdoor gatherings. in addition to the umbrellas and chairs, there are several cups scattered throughout the scene, adding to the casual and relaxed ambiance. a car can be seen parked near the picnic area, providing transportation for those attending the gathering. a white umbrella sitting on top of a wooden picnic table\n",
            "147 from scratch a man is holding an umbrella over his head as he walks along a bridge over a river. There are several other people in the scene, some of whom are also holding umbrellas to protect themselves from the rain. In total, there are four umbrellas visible in the image. Additionally, there is a car parked on the side of the road near the river, adding to the lively atmosphere of the scene. a man with an umbrella walking on a bridge over a river\n",
            "148 in 3D  There are two black suitcases placed side-by-side on a white background. One of the suitcases is slightly larger than the other, and they both appear to be made of carbon fiber material. The design of these suitcases is futuristic and sleek, showcasing the latest advancements in luggage technology. In total, there are six suitcases visible in the image, with three located on the left side and three on the right side of the larger suitcase. two pieces of luggage next to each other on a white background\n",
            "149 based on the image description a busy airport baggage claim area is filled with people and luggage carts. There are several men in blue shirts pushing luggage carts through the baggage claim area, indicating that they are responsible for transporting luggage from the airplane to the baggage claim area. In addition to the luggage carts, there are several suitcases scattered throughout the scene, likely belonging to passengers who have just arrived at the airport. Overall, the image captures the hustle and bustle of a busy airport baggage claim area. a baggage claim area at an airport filled with luggage carts\n",
            "150 based on the image description there are three stuffed teddy bears sitting together on a bed, with two of them positioned close to each other and the third one slightly further away from the others. There are also several pillows visible in the scene, providing a cozy and inviting atmosphere for the teddy bears. Additionally, a vase can be seen in the background, adding a decorative touch to the room. Overall, the image depicts a heartwarming scene of three stuffed teddy bears enjoying each other's company on a comfortable bed, surrounded by pillows and a vase. there are three stuffed teddy bears on a bed with pillows\n",
            "151 in photoshop/painter etc. there are three teddy bears lined up next to each other on a bookshelf, with a total of 10 books visible in the image. the teddy bears are arranged in a row, with the first one being closest to the viewer and the third one furthest from the viewer. there are also several smaller books scattered throughout the scene, adding to the overall bookish atmosphere of the image. there are four teddy bears lined up on a shelf\n",
            "152 based on the image description there are two bears, one brown and one black, standing next to each other in a dirt area. the brown bear appears to be the larger of the two, while the black bear is slightly smaller in size. both bears are standing on their hind legs, with their front paws resting on the ground. they appear to be exploring their surroundings, possibly searching for food or interacting with each other. a brown bear standing on top of some rocks in a dirt field\n",
            "153 based on the image description a group of people are playing frisbee on a sandy beach. There are at least six people involved in the game, with one person holding a frisbee in their hand. They are scattered across the beach, enjoying the outdoor activity and spending time together. In addition to the frisbee, there are several other items visible in the scene, such as a backpack, a cell phone, and a bottle of water. The beach setting provides a relaxed atmosphere for the group to engage in a fun and casual game of frisbee while soaking up the sun and enjoying each other's company. a group of people playing frisbee on a sandy beach\n",
            "154 from scratch a small, fluffy dog is lying on a bed next to a laptop computer. There are two cats visible in the image, one on the left side of the bed and another on the right side. Additionally, there is a pile of cushions on the bed, providing a cozy and comfortable environment for the dogs and cats. there is a small dog laying on a bed next to a laptop\n",
            "155 based on the image description there are two men playing frisbee in a wooded area. one man is throwing the frisbee, while the other man is trying to catch it. there are three frisbees visible in the scene, with one located near the man who is throwing the frisbee, another near the man who is trying to catch the frisbee, and the third one further away from the action. there are also several trees scattered throughout the scene, providing a natural backdrop for the frisbee game. a group of young men playing frisbee in a wooded area\n",
            "156 there are three zebras standing next to each other in a grassy field. Two of the zebras are on the left side of the image, while the third one is on the right side. The zebras appear to be grazing and enjoying the lush green surroundings. In addition to the zebras, there are several trees scattered throughout the field, adding to the natural beauty of the scene. a herd of zebras grazing on the grassy field\n",
            "157 based on the image description there are two women standing in front of a large brown horse. One woman is wearing a green shirt, while the other is wearing a blue shirt. Both women are holding onto the horse's reins, indicating that they are interacting with the horse. Additionally, there are several chairs scattered around the area, suggesting that this could be a farm or stable where the horse is being cared for. A man can also be seen sitting on one of the chairs, possibly observing the interaction between the women and the horse. Overall, the scene depicts a group of people interacting with a large horse in a farm or stable setting. a clydesdale horse standing next to a woman in a green shirt\n",
            "158 based on your description a plate filled with pancakes, bananas, and caramel sauce is displayed on a dining table. There are a total of 12 pancakes on the plate, with four bananas arranged around them. The caramel sauce is drizzled over the top of the pancakes, creating a tasty and visually appealing dish. a plate of pancakes with bananas and peanut butter\n",
            "159 based on this information  there is a person wearing a pink jacket standing in the middle of a snow-covered forest, surrounded by tall trees. The person is holding ski poles and appears to be skiing through the forest. In addition to the skier, there are two other people visible in the scene, one on the left and one on the right side of the image. They appear to be enjoying the snowy surroundings as well. a woman in a pink jacket is skiing through the woods\n",
            "160 based on this description Three cross-country skiers are making their way down a snowy slope, surrounded by pine trees. Two of the skiers are close to each other, while the third skier is slightly further away. In total, there are ten people visible in the scene, including the three skiers and seven others who appear to be enjoying the outdoor activity. a couple of people riding on skis down a snowy road\n",
            "161 from scratch a baseball game is taking place on the field, with a man wearing a baseball uniform pitching the ball. There are several people scattered around the field, watching the game and enjoying the atmosphere. Some of them are seated on benches, while others appear to be standing or walking around the field. A car can also be seen parked near the field, possibly belonging to one of the spectators. Overall, the scene depicts a lively and engaging baseball game in progress. a baseball player pitching the ball during a game in front of a crowd\n",
            "162 based on the image description  there are two bento boxes filled with a variety of colorful fruits and vegetables, such as apples, oranges, bananas, carrots, broccoli, and cauliflower. The bento boxes are placed on top of a pink tablecloth, creating a vibrant and healthy meal for the viewer to enjoy. there are two bento boxes filled with a variety of fruits and vegetables\n",
            "163 based on this information  there is a woman standing in the middle of a snow-covered road, wearing a pink jacket and skis on her feet. She is smiling and posing for the camera, surrounded by snow-covered evergreen trees. In addition to the woman, there are several ski poles scattered throughout the scene, indicating the presence of other skiers in the area. a woman riding skis down a snowy path A woman riding skis down a snowy path surrounded by pine trees. She is wearing a pink jacket and posing for the camera.\n",
            "164 based on the image description this image features a white plate filled with several crackers that have been spread with cream cheese. The crackers are arranged in a symmetrical pattern across the plate, creating a visually appealing display. In addition to the crackers and cream cheese, there is also a computer mouse placed on the table near the plate. Overall, the scene depicts a casual and inviting atmosphere, perfect for enjoying a snack or meal with friends or family. a plate of crackers with cream cheese on it, next to a keyboard\n",
            "165 based on this information  there is a woman skiing down a snow-covered slope, wearing a red jacket and black pants. She appears to be enjoying the experience, as she is smiling and posing for the camera. In addition to the skier, there are several ski poles scattered throughout the scene, indicating the presence of other skiers in the area. a woman in a red jacket skiing down a snowy slope\n",
            "166 There is a close-up image of a skateboarder wearing a pair of Vans shoes. The skateboarder is riding the skateboard, which is positioned on the left side of the image. In addition to the skateboarder's shoes, there are two pairs of sneakers visible in the scene. One pair of sneakers is located on the right side of the image, while the other pair can be found on the left side, near the skateboarder's shoes. a person is riding a skateboard with shoes on it\n",
            "167 based on the image description there is a bowl filled with a variety of vegetables, such as broccoli, tomatoes, and carrots. There is also a fork placed next to the bowl, indicating that the dish is meant to be eaten with a utensil. Additionally, there are two spoons placed on the table, one on the left side and one on the right side. The arrangement of the vegetables and utensils creates a visually appealing and nutritious meal. there is a bowl of vegetables on a table with a fork and spoon\n",
            "168 based on this description there is a skateboarder in mid-air, performing a trick on his skateboard. He is wearing jeans and a shirt, which can be seen in the image. There are several cars parked on the side of the road, including a red car, a blue car, and a truck. Additionally, there are two traffic lights visible in the scene, one on the left side and one on the right side of the image. a skateboarder is doing a trick in the street next to parked cars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nsDOcdIwZWzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "with open('description.csv', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "lines = [line.strip().split(',') for line in lines]\n",
        "\n",
        "for idx, line in enumerate(lines):\n",
        "    lines[idx] = [line[0], ','.join(line[1:])]\n",
        "\n",
        "df = pd.DataFrame(lines, columns=['id', 'desc'])\n",
        "embeddings = model.encode(df['desc'].tolist(), show_progress_bar=True)\n",
        "with open('embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump(embeddings, f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FUkIXsrDIhM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search\n"
      ],
      "metadata": {
        "id": "_206B6rZoKiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from usearch.index import Index\n",
        "\n",
        "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "with open('embeddings.pkl', 'rb') as f:\n",
        "    embeddings = pickle.load(f)\n",
        "embeddings = embeddings.astype('float32')\n",
        "\n",
        "index = Index(ndim=embeddings.shape[1], metric=\"cos\", dtype=\"f16\")\n",
        "num_results = 5\n",
        "\n",
        "for i, vector in enumerate(embeddings):\n",
        "    index.add(i, vector)\n",
        "\n",
        "index.save(\"index.usearch\")\n",
        "\n",
        "def _search(query):\n",
        "    query_embedding = model.encode(query)\n",
        "    query_embedding = np.array(query_embedding).astype('float32')\n",
        "    query_embedding = query_embedding.reshape(1, -1)\n",
        "    matches = index.search(query_embedding, num_results)\n",
        "    images = [f'images/{i}.jpg' for i in matches.keys]\n",
        "    return images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    query = gr.Textbox(lines=1, label='search query')\n",
        "    outputs = gr.Gallery(preview=True)\n",
        "    submit = gr.Button(value='search')\n",
        "    submit.click(_search, inputs=query, outputs=outputs)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "uA_wAO1ejpk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YvsRJvoEUW1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}